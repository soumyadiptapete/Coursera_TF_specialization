{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyadiptapete/Coursera_TF_specialization/blob/master/Exercise_7_Question.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11427
        },
        "outputId": "a2dde65d-4b72-4b03-9f26-19389acdacd9"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(include_top=False,weights=None, input_shape=(150,150,3))\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable=False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-15 13:02:42--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.197.128, 2607:f8b0:4001:c19::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  30.5MB/s    in 2.8s    \n",
            "\n",
            "2019-05-15 13:02:45 (30.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1553c890-de2f-4c68-de13-f8024b2528af"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks=myCallback()\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8350
        },
        "outputId": "6d43bec5-f907-4c5b-ffa8-d80fc9f5d0a3"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024,activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1,activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         38536192    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            1025        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "3f9cb590-c457-4895-d8ed-170835d988d2"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-15 13:11:40--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.197.128, 2607:f8b0:4001:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   117MB/s    in 1.2s    \n",
            "\n",
            "2019-05-15 13:11:41 (117 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-15 13:11:42--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.197.128, 2607:f8b0:4001:c01::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  52.5MB/s    in 0.2s    \n",
            "\n",
            "2019-05-15 13:11:42 (52.5 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6NHwRNnn0SH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f24e9ff-20ff-4e06-9012-752659cbe695"
      },
      "source": [
        "os.listdir('/tmp/training')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['humans', 'horses']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "99cc0d7d-1354-4cf8-8904-5917fa72b237"
      },
      "source": [
        "train_horses_dir = '/tmp/training/horses'\n",
        "train_humans_dir = '/tmp/training/humans'\n",
        "validation_horses_dir = '/tmp/validation/horses'\n",
        "validation_humans_dir ='/tmp/validation/humans'\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d90b85da-1d70-4d42-b383-3145eb7768ee"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,target_size=(150, 150),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "5f175e79-b6fb-4c59-ad97-3f38ebae2b47"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        callbacks=[callbacks])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "8/8 [==============================] - 1s 185ms/step - loss: 0.0313 - acc: 0.9961\n",
            "33/33 [==============================] - 12s 377ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 0.0313 - val_acc: 0.9961\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 0.0368 - acc: 0.9961\n",
            "33/33 [==============================] - 12s 354ms/step - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0368 - val_acc: 0.9961\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 0.1129 - acc: 0.9727\n",
            "33/33 [==============================] - 11s 348ms/step - loss: 0.0065 - acc: 0.9971 - val_loss: 0.1129 - val_acc: 0.9727\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 1s 163ms/step - loss: 0.0648 - acc: 0.9922\n",
            "33/33 [==============================] - 12s 356ms/step - loss: 0.0088 - acc: 0.9981 - val_loss: 0.0648 - val_acc: 0.9922\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 1s 161ms/step - loss: 0.0520 - acc: 0.9961\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "33/33 [==============================] - 11s 327ms/step - loss: 0.0020 - acc: 0.9990 - val_loss: 0.0520 - val_acc: 0.9961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "e00acb86-dba2-4a22-b820-e1f86f988435"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcTfX/wPHX2xj7zhRRqISxDGMs\nhSyltFFSiIRQCpP2QmRpX2kjES3kqxSVrxb8kJSxDCFL5ZtlMPZ9GT6/Pz5nxjVmuTNz5557576f\nj8d9zJ2z3fc5M/e8z/l8PufzEWMMSimlVD63A1BKKRUYNCEopZQCNCEopZRyaEJQSikFaEJQSinl\n0ISglFIK0ISgPIhImIgcEZHLfLmsm0TkShHxedtqEbleRLZ4/L5BRJp7s2w2PmuCiDyb3fWV8lZ+\ntwNQ2SciRzx+LQKcBM44vz9gjPksK9szxpwBivl62VBgjKnui+2ISG+gmzGmpce2e/ti20plRhNC\nEDPGpJyQnSvQ3saYn9JbXkTyG2OS/BGbUpnR/8fAo0VGeZiIjBKRL0RkqogcBrqJyNUislREDohI\ngoiMEZFwZ/n8ImJEpIrz+6fO/DkiclhEfhWRqlld1pl/k4hsFJGDIjJWRH4RkR7pxO1NjA+IyGYR\n2S8iYzzWDRORN0Vkr4j8DbTN4PgMFpFpqaa9KyJvOO97i8h6Z3/+cq7e09vWNhFp6bwvIiKfOLGt\nBRqkWnaIiPztbHetiLRzptcB3gGaO8VxezyO7XCP9R909n2viHwtIhW8OTZZOc7J8YjITyKyT0R2\nisiTHp8z1Dkmh0QkTkQuSat4TkQWJ/+dneO50PmcfcAQEakmIvOdz9jjHLeSHutXdvYx0Zn/togU\ncmKu6bFcBRE5JiJl09tf5QVjjL7ywAvYAlyfatoo4BRwGzb5FwYaAo2xd4eXAxuB/s7y+QEDVHF+\n/xTYA8QA4cAXwKfZWPYi4DDQ3pn3KHAa6JHOvngT4zdASaAKsC9534H+wFqgElAWWGj/zdP8nMuB\nI0BRj23vBmKc329zlhGgNXAcqOvMux7Y4rGtbUBL5/1rwAKgNFAZWJdq2buBCs7f5B4nhoudeb2B\nBani/BQY7ry/wYmxHlAIeA+Y582xyeJxLgnsAmKBgkAJoJEz7xkgHqjm7EM9oAxwZepjDSxO/js7\n+5YE9APCsP+PVwHXAQWc/5NfgNc89ucP53gWdZZv6swbD4z2+JzHgJlufw+D/eV6APry0R8y/YQw\nL5P1Hgf+47xP6yT/gcey7YA/srFsL2CRxzwBEkgnIXgZYxOP+V8BjzvvF2KLzpLn3Zz6JJVq20uB\ne5z3NwEbMlj2W+Bh531GCeFfz78F8JDnsmls9w/gFud9ZglhMvCCx7wS2HqjSpkdmywe53uBZeks\n91dyvKmme5MQ/s4kho7Jnws0B3YCYWks1xT4BxDn91VAB19/r0LtpUVGed9Wz19EpIaIfOcUARwC\nRgDlMlh/p8f7Y2RckZzespd4xmHsN3hbehvxMkavPgv4XwbxAnwOdHHe3+P8nhzHrSLym1OccQB7\ndZ7RsUpWIaMYRKSHiMQ7xR4HgBpebhfs/qVszxhzCNgPVPRYxqu/WSbH+VLsiT8tGc3LTOr/x/Ii\nMl1EtjsxfJwqhi3GNmA4jzHmF+zdRjMRqQ1cBnyXzZiUQxNC3pe6yeU47BXplcaYEsBz2Cv23JSA\nvYIFQESE809gqeUkxgTsiSRZZs1ipwPXi0hFbJHW506MhYEZwIvY4pxSwA9exrEzvRhE5HLgfWyx\nSVlnu396bDezJrI7sMVQydsrji2a2u5FXKlldJy3Aleks1568446MRXxmFY+1TKp9+9lbOu4Ok4M\nPVLFUFlEwtKJYwrQDXs3M90YczKd5ZSXNCGEnuLAQeCoUyn3gB8+81sgWkRuE5H82HLpiFyKcTrw\niIhUdCoYn8poYWPMTmyxxsfY4qJNzqyC2HLtROCMiNyKLev2NoZnRaSU2Oc0+nvMK4Y9KSZic2Mf\n7B1Csl1AJc/K3VSmAveLSF0RKYhNWIuMMenecWUgo+M8C7hMRPqLSEERKSEijZx5E4BRInKFWPVE\npAw2Ee7ENl4IE5G+eCSvDGI4ChwUkUuxxVbJfgX2Ai+IragvLCJNPeZ/gi1iugebHFQOaUIIPY8B\n92ErecdhK39zlTFmF9AJeAP7Bb8CWIm9MvR1jO8DPwNrgGXYq/zMfI6tE0gpLjLGHAAGATOxFbMd\nsYnNG8OwdypbgDl4nKyMMauBscDvzjLVgd881v0R2ATsEhHPop/k9f+LLdqZ6ax/GdDVy7hSS/c4\nG2MOAm2AO7FJaiPQwpn9KvA19jgfwlbwFnKKAvsAz2IbGFyZat/SMgxohE1Ms4AvPWJIAm4FamLv\nFv7F/h2S52/B/p1PGmOWZHHfVRqSK2SU8hunCGAH0NEYs8jteFTwEpEp2Irq4W7Hkhfog2nKL0Sk\nLbZFz3Fss8XT2KtkpbLFqY9pD9RxO5a8QouMlL80A/7Glp3fCNyhlYAqu0TkReyzEC8YY/51O568\nQouMlFJKAXqHoJRSyuFVHYKITMTW9u82xtROY74Ab2OfCj2GfTJxhTPvPmCIs+goY8xkZ3oDbFO/\nwsD3QKzJ5HalXLlypkqVKt6ErJRSyrF8+fI9xpiMmnoD3lcqf4ztdCu9tr43Yfs1qYbtG+V9oLHT\nNnkYtn8bAywXkVnGmP3OMn2wzdK+x3ZCNiejIKpUqUJcXJyXISullAIQkcye2Ae8LDIyxizEtsVO\nT3tgirGWAqWcHhhvBH40xuxzksCPQFtnXgljzFLnrmAKcLs3sSillModvqpDqMj5fZRsc6ZlNH1b\nGtMvICJ9ne514xITE30UrlJKqdQCvlLZGDPeGBNjjImJiMi0CEwppVQ2+SohbOf8zrwqOdMyml4p\njelKKaVc4quEMAvo7nR01QQ4aIxJAOYCN4hIaREpje0+eK4z75CINHFaKHXHDuqhlFLKJd42O50K\ntATKicg2bMuhcABjzAfYVkI3A5uxzU57OvP2ichIbCdjACOMMcmV0w9xrtnpHDJpYaSUUip3BdWT\nyjExMUabnSqlVNaIyHJjTExmy2nndkopFUiOHoWdOyEh4fyfTzwBpUrl6kdrQlBKqdx29izs3Xvh\nST4h4cJphw9fuH7+/NCliyYEpZQKWCdO2JN4Wlf0nj937YKkpAvXL14cypeHChUgOvrc+9Q/y5aF\nfLn/lIAmBKWU8mQMHDiQ9tV76p/791+4vghcdNG5E3qdOmmf5MuXh6JF/b9/GdCEoJQKDadP2yv1\nzIpsdu6Ek2kM1VG48LkTeWQktG59/gk++X1EhC3iCULBGbVSSoG9mj98OP2reM/3e/akvY1y5c6d\n1K+6Ku2r+QoVbPGOiH/3z880ISilAs+ZM5CYmHGRTfL7Y8cuXL9AgXMn88svh6ZN0y6yufhiu6wC\nNCEopfzp2LH0i2o8f+7ebVvmpFaq1LkTepMm6VfCli6d56/mc4MmBKVUziQ3qcyspc3OnXDo0IXr\nh4XZK/UKFeCSS6BBgwvL5StUsMsULuz//QshmhCUUmk7edK7k/zOnWk3qSxW7NwJvV69tMvly5e3\nZfh+aFKpMqcJQalQ4tmkMrOTfXpNKiMizp3Qa9dOv0llsWL+3z+VI5oQlMoL0mtSmdbPtJpUFip0\n7kReowa0bHlhkU358rZ9fZA2qVSZ07+sUoEqsyaVnj/37LHLp1a27LkTevPmaRfZVKgAJUpoJazS\nhKCU33nTpDL5Z1pNKsPDz53Iq1aFa65Ju3z+oougYEH/758KWpoQlPKVY8e8O8mn16SyZMlzJ/RG\njdJvUlmmjF7Nq1yhCSHUnD1rr04zO2ml1TxQpe/48bR7qcyX71yTytQdmKVuUlmkiP/jVsqDJoS8\n4vjx83tdTO9kv2uXLbJIrUSJcyeomBh7tapXod5LfjI2rSaVYWFuR6eUVzQhBDJjYN++zDvjSkiA\ngwcvXD9fvnO9LlaoYNuCp9dEUK9OlQp5mhDccOqUvVL3ZrCM06cvXL9IkXMn8tq14frr0+91Ua9O\nlVJe0oTgK8bYcndvOuPauzftbZQrd+6EXqNG+lfzIdDrolLK/zQhZCYpybYK8aYt+PHjF65foMC5\nE3m1aufagqfV62J4uP/3TymlHKGbEI4ezbxcfudOmwzSeuCnVKlzJ/arr06/D/VSpfRqXikVFEIi\nIUzu+gMbVhyFo0fgyFE4cgROn7pwQSkBRStAsaK2H5byxeDKYvZ9UWdasaJQtFjaj+/vc15rc3uP\ncl90NHTs6HYUSoU2Y2DJEpg2Dd54I/cLEUIiIXy1sCxztrW0V+rJV+thzk9J9fOkwEkgnWL+UHDm\njK2LbtrU3uQopfxr506YMgUmToQNG+y1aK9eUL9+7n5uSCSEb7Y2cDuEoLJpE1SvDh98AM8/73Y0\nSoWG06fh++9tEvjuO3th1qwZPP20vVv3R+ex2gm5ukC1anDzzTYhpNUxplLKd/78E558Ei69FG6/\nHX7/HR5/3N4ZLFoEPXr4rydxTQgqTbGxtj592jS3I1Eq7zlyxN4JNG0KNWvCm2/atimzZsHWrfDS\nS3DVVf6PS0xaLWgCVExMjImLi3M7jJBgjH3mrWBBWL5cG0oplVPJFcQTJ8IXX9iGjjVqwP33w733\n2pbnuUVElhtjYjJbzqs7BBFpKyIbRGSziDydxvzKIvKziKwWkQUiUslj3ssi8ofz6uQx/WMR+UdE\nVjmvet7unMp9IjBwIKxcCYsXux2NUsFr50545RV7J9CsGUyfDp07wy+/wLp1tngoN5NBVmSaEEQk\nDHgXuAmIBLqISGSqxV4Dphhj6gIjgBeddW8BooF6QGPgcREp4bHeE8aYes5rVY73RvlUt272MYox\nY9yORKngcvq0Lf5p3x4qVYKnnrIdEUycaB9xmjDBDmMRaHfe3twhNAI2G2P+NsacAqYB7VMtEwnM\nc97P95gfCSw0xiQZY44Cq4G2OQ9b+UPRotCnD8ycCf/+63Y0SgW+DRvsyf+yy2wy+O03eOwxW3G8\neDH07BnYQ017kxAqAls9ft/mTPMUD3Rw3t8BFBeRss70tiJSRETKAa2ASz3WG+0UM70pImkO7SQi\nfUUkTkTiEhMTvQhX+dLDD9uyz3ffdTsSpQLTkSMwaZItDqpRA15/HRo3hm++sRXEL79sm3EHA1+1\nMnocaCEiK4EWwHbgjDHmB+B7YAkwFfgVSO6M/xmgBtAQKAM8ldaGjTHjjTExxpiYiIgIH4WrvFW5\nMtxxB3z4oa0EU0qdqyDu3ds+vNmrlx3W+pVXYNs2+PpraNcu+Lon8yYhbOf8q/pKzrQUxpgdxpgO\nxpj6wGBn2gHn52injqANIMBGZ3qCsU4Ck7BFUyoAxcbC/v3w6aduR6KUu3btgldfhchI22R02jS4\n+25bQbx+PTzxhO3KLFh5kxCWAdVEpKqIFAA6A7M8FxCRciKSvK1ngInO9DCn6AgRqQvUBX5wfq/g\n/BTgduCPnO+Oyg3NmtlH5seMSbufP6XysqQkmD3bPjRWsaJ9iKxsWfjoI9uC6KOPArOCODsy7brC\nGJMkIv2BuUAYMNEYs1ZERgBxxphZQEvgRRExwELgYWf1cGCRPedzCOhmjEly5n0mIhHYu4ZVwIO+\n2y3lSyL2LqFHD/jpJ2jTxu2IlMp9GzbYuoHJk+2J/+KLbQVxz562riAv0gfTlFdOnrQtJxo1sldL\nSuVFR47Af/5jm4cuXmw7ebzlFvvw2E03BV+dQDKfPpimVMGC8MADttOtzZvdjkYp3zEGfv31/Ari\n3btt66Bt22xroWCsIM4OTQjKa/362WEgxo51OxKlcm7XLnjtNahVy9YBTJsGd91l7wySO5wL5gri\n7NCEoLxWoYJtUTFpkh0+Wqlgk1xBfMcd9gniJ56A0qVtxXBCwrkO5/JCBXF2aEJQWRIbC4cP26Sg\nVLDYuNGOK3Dppbb4Z8kSGDTINhX95RdbTFS8uNtRui8kBshRvtOwoe2md+xY6N/fVropFYiOHIEZ\nM+xV/6JF9n/15pttBfHNN4dGnUBW6R2CyrLYWPjrLzu6k1KBJLmCuE8fW8TZs6etK3jpJduNRHKH\nc5oM0qZ3CCrLOnSwD+i8/Tbcdpvb0ShlWwV98omtC1i/HooUgU6dbFFQKNcJZJXeIagsCw+3nd79\n/DOsXet2NCpUJSXBt9+eu0B5/HHbXfuECfZBsokT7VP2mgy8pwlBZUufPlCokI6VoPxv0yZ45hn7\noORtt9lK4UcesYPNLFli6wi0gjh7tMhIZUu5ctC1q71Nf/FFKFPG7YhUXnb0qK0g/uij8yuIe/Wy\nTxJrnYBv6B2CyrbYWDh+3HaNrZSvGQNLl0LfvraCuEcPWxT00kt2wKZZs2yHc5oMfEfvEFS21akD\nrVrZwXMee8w+xaxUTiVXEE+caIuBihSxD0T26qV1ArlN7xBUjsTG2uZ8M2e6HYkKZklJtp8szwri\nkiXt3WdCgn0QsnlzTQa5Ta/pVI7ceitUrWqboN51l9vRqGCzadO5LqZ37ICICHuR0auXHYRG+Zcm\nBJUjYWEwYAA8+igsXw4NGrgdkQp0SUnw2We2SGjhQsiXz1YQv/OOvcDQOgH3aJGRyrFevaBoUW2C\nqrwzbJitIE5IsC3Utm491+GcJgN3aUJQOVaypP2CT5tmuwlQKj07d8Jbb9mniDdssB3OXXKJ21Gp\nZJoQlE8MGACnTsEHH7gdiQpkL75oR98bNUoriAORJgTlE9Wr2yEG33/ffuGVSu3ff+0FQ8+ecOWV\nbkej0qIJQflMbKwtMpo+3e1IVCAaOdL+HDrU3ThU+jQhKJ+54QaoUcM2QTXG7WhUIEluXvrgg7YP\nIhWYNCEonxGBgQNt89MlS9yORgWS4cOhYEF49lm3I1EZ0YSgfKp7d9vqSJugqmR//AFTp9qLhYsv\ndjsalRFNCMqnihaF3r3hyy9t+3Klhg613VE/8YTbkajMaEJQPte/v61DeO89tyNRblu2DL7+2vZN\npF2kBz5NCMrnqlSx49aOHw/HjrkdjXLTkCF27IxHHnE7EuUNTQgqV8TGwr59ts8aFZoWLoQffrBP\nI+sIZsFBTBC1D4yJiTFxcXFuh6G8YAzUr287MluzRp9KDTXGwLXXwt9/w+bNULiw2xGFNhFZboyJ\nyWw5vUNQuULE3iWsXQvz5rkdjfK3uXNh8WJbZKTJIHh4lRBEpK2IbBCRzSLydBrzK4vIzyKyWkQW\niEglj3kvi8gfzquTx/SqIvKbs80vRKSAb3ZJBYouXWz/9m+/7XYkyp+MsYmgShU74L0KHpkmBBEJ\nA94FbgIigS4iknroiteAKcaYusAI4EVn3VuAaKAe0Bh4XERKOOu8DLxpjLkS2A/ov04eU6gQPPAA\nfPst/PWX29Eof5k50z6cOHw4FNDLvKDizR1CI2CzMeZvY8wpYBrQPtUykUBywcB8j/mRwEJjTJIx\n5iiwGmgrIgK0BmY4y00Gbs/+bqhA1a+fHUTnnXfcjkT5w5kz9u6gRg3o1s3taFRWeZMQKgKejxht\nc6Z5igc6OO/vAIqLSFlnelsRKSIi5YBWwKVAWeCAMSYpg20CICJ9RSROROISExO92ScVQC65xA6t\nOXEiHD7sdjQqt33+OaxfDyNG2AsBFVx8Van8ONBCRFYCLYDtwBljzA/A98ASYCrwK3AmKxs2xow3\nxsQYY2IiIiJ8FK7yp9hYOHQIPv7Y7UhUbjp92hYT1asHd97pdjQqO7xJCNuxV/XJKjnTUhhjdhhj\nOhhj6gODnWkHnJ+jjTH1jDFtAAE2AnuBUiKSP71tqryjcWP7GjsWzp51OxqVWyZOtM1MR42y4ySr\n4OPNn20ZUM1pFVQA6AzM8lxARMqJSPK2ngEmOtPDnKIjRKQuUBf4wdiHH+YDHZ117gO+yenOqMAV\nG2u7QJ4zx+1IVG44ccKOd3D11XDzzW5Ho7Ir04TglPP3B+YC64Hpxpi1IjJCRNo5i7UENojIRuBi\nYLQzPRxYJCLrgPFAN496g6eAR0VkM7ZO4SMf7ZMKQB072voEbYKaN73/PmzfDi+8oA8hBjN9Uln5\nzejRtgXK2rUQmbrhsgpaR47A5ZdDVBT8+KPb0ai06JPKKuD07WsHSRk71u1IlC+9/TYkJtqEr4Kb\nJgTlNxERcM89MGUK7N/vdjTKF/bvh1dfhXbtoFEjt6NROaUJQflVbKztEnvCBLcjUb7w2mu2SfHI\nkW5HonxBE4Lyq6goaNHCPrmclJT58ipw7d5ti4s6dYK6dd2ORvmCJgTld7Gx8O+/8I02NA5qL75o\nm5s+/7zbkShf0YSg/K5dO9sTpjZBDV7bttmmpvfdB1dd5XY0ylc0ISi/Cwuz4y4vWgQrV7odjcqO\nkSPtU+fPPed2JMqXNCEoV9x/PxQtCmPGuB2Jyqq//rLdVDzwAFSu7HY0ypc0IShXlCplixs+/9xW\nTqrgMXw4hIfD4MFuR6J8TROCcs2AAXDqFIwb53Ykyltr18Jnn9m/XfnybkejfE0TgnJNjRpw443w\n3ns2MajA99xzULw4PPmk25Go3KAJQbkqNhZ27oT//MftSFRm4uLgq6/g0UehbFm3o1G5QROCctWN\nN9pmi2+/bQdnV4FryBCbCAYNcjsSlVs0IShX5csHAwfCsmWwdKnb0aj0LFoEc+fCU09BiRJuR6Ny\niyYE5br77oOSJbUJaqAyxrYoKl8eHn7Y7WhUbtKEoFxXrJh9LmHGDDvIigosP/xg7xCGDIEiRdyO\nRuUmTQgqIPTvD2fO2BZHKnAYYxNB5crQp4/b0ajcpglBBYSqVW0fR+PGwfHjbkejkn39tW1dNGwY\nFCjgdjQqt2lCUAEjNhb27rVPLyv3nTkDQ4dC9epw771uR6P8QROCChgtW9p+9bUJamCYNs0+mTxi\nBOTP73Y0yh80IaiAIWKboK5ZAwsWuB1NaDt92hYTRUVBx45uR6P8RROCCij33GMfftKxEtz18ce2\nV9NRo+yzIio06J9aBZTChW23yrNmwT//uB1NaDpxwhYTNWkCt9zidjTKnzQhqIDz0EP2qvSdd9yO\nJDSNG2dHRBs92hbjqdChCUEFnIoVbbn1Rx/BkSNuRxNajh6FF16A1q3tS4UWTQgqIMXGwsGDMHmy\n25GEljFj7IBFo0e7HYlygyYEFZCaNIGGDe0J6uxZt6MJDQcOwCuvwK232uOvQo8mBBWQROxdwsaN\ntpdNlftef90mhZEj3Y5EucWrhCAibUVkg4hsFpGn05hfWUR+FpHVIrJARCp5zHtFRNaKyHoRGSNi\nq6mc5TaIyCrndZHvdkvlBXfdBRUqaBNUf9i9G958E+6+G+rVczsa5ZZME4KIhAHvAjcBkUAXEYlM\ntdhrwBRjTF1gBPCis+41QFOgLlAbaAi08FivqzGmnvPSodbVeQoUgH797B3Cn3+6HU3e9tJLtg+p\n5593OxLlJm/uEBoBm40xfxtjTgHTgPaplokE5jnv53vMN0AhoABQEAgHduU0aBU6HnjAJoaxY92O\nJO/ats32Mtu9ux3nWoUubxJCRWCrx+/bnGme4oEOzvs7gOIiUtYY8ys2QSQ4r7nGmPUe601yiouG\nJhclpSYifUUkTkTiEhMTvQhX5SUXXWSfXp482ZZvK98bNcpW3A8b5nYkym2+qlR+HGghIiuxRULb\ngTMiciVQE6iETSKtRaS5s05XY0wdoLnzSrM/RWPMeGNMjDEmJiIiwkfhqmAycKBtH//RR25Hkvf8\n/bc9rn36QJUqbkej3OZNQtgOXOrxeyVnWgpjzA5jTAdjTH1gsDPtAPZuYakx5ogx5ggwB7jamb/d\n+XkY+BxbNKXUBerXh+bN7ZPLZ864HU3eMny47cl08GC3I1GBwJuEsAyoJiJVRaQA0BmY5bmAiJQT\nkeRtPQNMdN7/i71zyC8i4di7h/XO7+WcdcOBW4E/cr47Kq+KjYUtW2wfR8o31q2DTz+1o9Vdconb\n0ahAkGlCMMYkAf2BucB6YLoxZq2IjBCRds5iLYENIrIRuBhIfs5xBvAXsAZbzxBvjJmNrWCeKyKr\ngVXYO44PfbZXKs9p3x4uu0yboPrSc8/Z8ayfesrtSFSgEBNEI5HExMSYuLg4t8NQLnn1VXjySVi5\nUtvK59SKFdCggU0K2tQ07xOR5caYmMyW0yeVVdDo3RuKFNEmqL4wZAiULg2PPup2JCqQaEJQQaN0\nadtW/rPPQFsgZ98vv8CcObaoqGRJt6NRgUQTggoqAwbAyZMwfrzbkQQnY2yLovLlbWWyUp40Iaig\nEhkJbdrYJ2tPn3Y7muDz00/wf/9nk0LRom5HowKNJgQVdGJjYccOmDHD7UiCS/LdwWWX2QfRlEpN\nE4IKOjfdBNWqaRPUrJo1C5Yts11UFCzodjQqEGlCUEEnXz5bl/Dbb/alMnf2LAwdClddZSvmlUqL\nJgQVlHr0gBIl9C7BW198AWvW2GcO8ud3OxoVqDQhqKBUvDj06gX/+Y+tT1DpS0qyxUR169oBcJRK\njyYEFbQGDLCd3b3/vtuRBLbJk2HTJjs0Zj79xqsM6L+HClqXXw633QbjxsGJE25HE5hOnrTFRI0a\n2WOlVEY0IaigNnCgfWp56lS3IwlM48bB1q0wejSkPQSVUudo53YqqBljy8bDwmynd3rSO+foUXsX\nFRkJ8+bpsQll2rmdCgki9i4hPh4WLnQ7msAydizs3q13B8p7mhBU0OvaFcqU0Saong4cgFdegZtv\nhmuucTsaFSw0IaigV6QI9O0L33xjR1VT8MYbsH8/jBrldiQqmGhCUHnCQw/ZYpF333U7EvclJsKb\nb0LHjnY8aqW8pQlB5QmXXgp33gkTJtjK1FD28stw7BiMGOF2JCrYaEJQeUZsrC07nzLF7Ujcs2OH\nvUvq1g1q1nQ7GhVsNCGoPOPqq+04wWPG2M7cQtGoUee6qlAqqzQhqDxDxN4l/Pkn/Pij29H43z//\nwIcf2rGnL7/c7WhUMNKEoPKUu++Giy8OzSaoyT2ZDhnidiQqWGlCUHlKwYLQr58dRH7DBrej8Z/1\n6+GTT+Dhh6FiRbejUcFKE4Lj5FIJAAAaQ0lEQVTKcx58EAoUgHfecTsS/xk2zD6P8fTTbkeigpkm\nBJXnXHwxdO4MH38MBw+6HU3uW7nSjgsxaBCUK+d2NCqYaUJQedLAgXDkCEyc6HYkuW/oUChdGh57\nzO1IVLDThKDypAYNoGlT28HbmTNuR5N7fv0VvvsOnnwSSpZ0OxoV7DQhqDwrNtY2xfz2W7cjyR3G\nwLPP2iKyAQPcjkblBZoQVJ51xx22S4u82gT1559hwQKbFIoWdTsalRd4lRBEpK2IbBCRzSJyQTsG\nEaksIj+LyGoRWSAilTzmvSIia0VkvYiMEbE9s4tIAxFZ42wzZbpSvpI/v22GOX8+rF7tdjS+ZQwM\nHmwT3gMPuB2NyisyTQgiEga8C9wERAJdRCQy1WKvAVOMMXWBEcCLzrrXAE2BukBtoCHQwlnnfaAP\nUM15tc3pziiVWp8+ULiw7c4iL5k9G37/HZ57zj57oZQveHOH0AjYbIz52xhzCpgGtE+1TCQwz3k/\n32O+AQoBBYCCQDiwS0QqACWMMUuNHcNzCnB7jvZEqTSUKQP33guffQZ79rgdjW+cPWtbFl15Jdx3\nn9vRqLzEm4RQEdjq8fs2Z5qneKCD8/4OoLiIlDXG/IpNEAnOa64xZr2z/rZMtgmAiPQVkTgRiUtM\nTPQiXKXON3AgnDhh+/nJC6ZPt0Vgzz8P4eFuR6PyEl9VKj8OtBCRldgioe3AGRG5EqgJVMKe8FuL\nSPOsbNgYM94YE2OMiYmIiPBRuCqU1KoF119vu4U+fdrtaHImuSfT2rXtw3dK+ZI3CWE7cKnH75Wc\naSmMMTuMMR2MMfWBwc60A9i7haXGmCPGmCPAHOBqZ/1KGW1TKV8aOBC2b4evvnI7kpyZMgU2boSR\nIyGfthFUPubNv9QyoJqIVBWRAkBnYJbnAiJSTkSSt/UMkPx86L/YO4f8IhKOvXtYb4xJAA6JSBOn\ndVF34Bsf7I9SabrlFrjiiuBugnrypC0matgQ2qeuxVPKBzJNCMaYJKA/MBdYD0w3xqwVkREi0s5Z\nrCWwQUQ2AhcDo53pM4C/gDXYeoZ4Y8xsZ95DwARgs7PMHJ/skVJpyJfPPrz166+wbJnb0WTPhx/C\nv//aQXC0kbbKDWIb+QSHmJgYExcX53YYKkgdOgSVKkG7dvDpp25HkzXHjtk7nKuusg+jaUJQWSEi\ny40xMZktp6WQKmSUKAE9e9pWOgkJbkeTNe+8Azt3wujRmgxU7tGEoELKgAG2pc4HH7gdifcOHoSX\nX4a2baFZM7ejUXmZJgQVUq680lYwf/CBraQNBm++Cfv22boDpXKTJgQVcmJjYfdumDbN7Ugyt3cv\nvPEGdOhgu/RWKjdpQlAh57rrIDLSNkEN9DYVL79sB/oZOdLtSFQo0ISgQo6IfVBt5UpYvNjtaNKX\nkGArk7t1swlMqdymCUGFpHvvtcNOBvKDaqNH2642hg93OxIVKjQhqJBUpIjtGnvmTPjf/9yO5kJb\ntsD48XD//XD55W5Ho0KFJgQVsh5+2BYfvfee25FcaMQI+3T1kCFuR6JCiSYEFbIuu8wOs/nhh3D0\nqNvRnPPnnzB5Mjz0kH2yWil/0YSgQlpsLOzfH1hdWQwbZkd5e/qCwWqVyl2aEFRIa9oUoqPtEJuB\n0AR11SrbtcYjj8BFF7kdjQo1mhBUSEtugrpuHfz0k9vR2KExS5WCxx93OxIVijQhqJDXubO9Gne7\nCerSpfDtt/DEEzYpKOVvmhBUyCtYEB58EL77DjZtci+OwYNtYho40L0YVGjThKAU0K+fHbB+7Fh3\nPn/ePPt65hkoVsydGJTShKAUUL48dOoEkybZgXT8yRh7d1Cpkr1TUcotmhCUcsTG2o7kJk3y7+d+\n952tPxg6FAoV8u9nK+VJh9BUykPTprBrF2zYAGFhuf95Z8/aZq9HjsD69bbYSilf0yE0lcqG2Fj4\n6y/4/nv/fN6MGRAfbzuw02Sg3KZ3CEp5OH0aqlaFGjVy/7mEpCSoXdveiaxe7Z87EhWavL1DyO+P\nYHLT6dOn2bZtGydOnHA7FBUgChUqRKVKlQjPxiV3eLjt9O7ZZ+GPP+wJO7d8+qktmvryS00GKjAE\n/R3CP//8Q/HixSlbtiwi4lJkKlAYY9i7dy+HDx+matWq2drG3r22xc+999ouqHPDqVNQvTqULQvL\nltknppXKLSFTh3DixAlNBiqFiFC2bNkc3TGWLWtHKfv0U5sccsOECXbMg1GjNBmowBH0CQHQZKDO\n44v/h4ED4fhxe+L2tWPHbCJo1gxuvNH321cqu/JEQlDK1+rUgdat4d13beWvL733nh0v+YUX9O5A\nBRZNCDm0d+9e6tWrR7169ShfvjwVK1ZM+f3UqVNebaNnz55s2LAhw2XeffddPvvsM1+ErLwUGwtb\nt9phNn3l0CF46SV7Z9C8ue+2q5QvBH2l8vr166lZs6ZLEZ1v+PDhFCtWjMdT9V1sjMEYQ758oZV/\nk5KSyJ/fnYZsvvi/OHMGqlWDSy6BxYt9E9fzz9tnDpYtg5hMq/iU8g2fViqLSFsR2SAim0XkgnGc\nRKSyiPwsIqtFZIGIVHKmtxKRVR6vEyJyuzPvYxH5x2Nevazu5AUeeQRatvTt65FHshXK5s2biYyM\npGvXrtSqVYuEhAT69u1LTEwMtWrVYsSIESnLNmvWjFWrVpGUlESpUqV4+umniYqK4uqrr2b37t0A\nDBkyhLfeeitl+aeffppGjRpRvXp1lixZAsDRo0e58847iYyMpGPHjsTExLBq1aoLYhs2bBgNGzak\ndu3aPPjggyRfFGzcuJHWrVsTFRVFdHQ0W7ZsAeCFF16gTp06REVFMXjw4PNiBti5cydXXnklABMm\nTOD222+nVatW3HjjjRw6dIjWrVsTHR1N3bp1+fbbb1PimDRpEnXr1iUqKoqePXty8OBBLr/8cpKc\nMpr9+/ef97u/hYXBgAHwyy+wfHnOt7d3L7z+uh22U5OBCkSZJgQRCQPeBW4CIoEuIhKZarHXgCnG\nmLrACOBFAGPMfGNMPWNMPaA1cAz4wWO9J5LnG2MuPHMFuT///JNBgwaxbt06KlasyEsvvURcXBzx\n8fH8+OOPrFu37oJ1Dh48SIsWLYiPj+fqq69m4sSJaW7bGMPvv//Oq6++mpJcxo4dS/ny5Vm3bh1D\nhw5l5cqVaa4bGxvLsmXLWLNmDQcPHuS///0vAF26dGHQoEHEx8ezZMkSLrroImbPns2cOXP4/fff\niY+P57HHHst0v1euXMlXX33Fzz//TOHChfn6669ZsWIFP/30E4MGDQIgPj6el19+mQULFhAfH8/r\nr79OyZIladq0aUo8U6dO5a677nLtLgOgVy/b+6gvxkp45RXbRcXIkTnfllK5wZtvWiNgszHmbwAR\nmQa0BzzPZpHAo877+cDXaWynIzDHGHMs++FmwrmCDhRXXHEFMR6XglOnTuWjjz4iKSmJHTt2sG7d\nOiIjz8+thQsX5qabbgKgQYMGLFq0KM1td+jQIWWZ5Cv5xYsX89RTTwEQFRVFrVq10lz3559/5tVX\nX+XEiRPs2bOHBg0a0KRJE/bs2cNtt90G2Ie7AH766Sd69epF4cKFAShTpkym+33DDTdQunRpwCau\np59+msWLF5MvXz62bt3Knj17mDdvHp06dUrZXvLP3r17M2bMGG699VYmTZrEJ598kunn5aaSJaFH\nDxg3zp7Qy5fP3nYSEmzX2vfcA+n8WZRynTdFRhWBrR6/b3OmeYoHOjjv7wCKi0jZVMt0Bqammjba\nKWZ6U0QKpvXhItJXROJEJC4xMdGLcANH0aJFU95v2rSJt99+m3nz5rF69Wratm2bZlv5AgUKpLwP\nCwtLt7ikYMGCmS6TlmPHjtG/f39mzpzJ6tWr6dWrV7ba7OfPn5+zZ88CXLC+535PmTKFgwcPsmLF\nClatWkW5cuUy/LwWLVqwceNG5s+fT3h4ODVq1MhybL42YIDt0mLcuOxv44UX7MNow4f7LCylfM5X\ntZyPAy1EZCXQAtgOnEmeKSIVgDrAXI91ngFqAA2BMsBTaW3YGDPeGBNjjImJiIjwUbj+d+jQIYoX\nL06JEiVISEhg7ty5ma+URU2bNmX69OkArFmzJs0iqePHj5MvXz7KlSvH4cOH+fLLLwEoXbo0ERER\nzJ49G7An+WPHjtGmTRsmTpzI8ePHAdi3bx8AVapUYblTsD5jxox0Yzp48CAXXXQR+fPn58cff2T7\n9u0AtG7dmi+++CJle8k/Abp160bXrl3p2bNnjo6Hr1x1Fdx8M7z/Ppw8mfX1//c/m0x69QKnqkWp\ngORNQtgOXOrxeyVnWgpjzA5jTAdjTH1gsDPtgMcidwMzjTGnPdZJMNZJYBK2aCrPio6OJjIykho1\natC9e3eaNm3q888YMGAA27dvJzIykueff57IyEhKlix53jJly5blvvvuIzIykptuuonGjRunzPvs\ns894/fXXqVu3Ls2aNSMxMZFbb72Vtm3bEhMTQ7169XjzzTcBeOKJJ3j77beJjo5m//796cZ07733\nsmTJEurUqcO0adOoVq0aYIu0nnzySa699lrq1avHE088kbJO165dOXjwIJ06dfLl4cmR2FjbLbaT\nb7NkxAj7vMHQob6PSymfSm4Smd4LW8/wN1AVKIAtHqqVaplyQD7n/WhgRKr5S4FWqaZVcH4K8Bbw\nUmaxNGjQwKS2bt26C6aFqtOnT5vjx48bY4zZuHGjqVKlijl9+rTLUWXd1KlTTY8ePXK0DV//X5w9\na0zNmsY0aGDfe2vDBmPCwoyJjfVpOEplCRBnMjm/GmMyr1Q2xiSJSH9scU8YMNEYs1ZERjgfMgto\nCbwoIgZYCDycvL6IVMHeYfxfqk1/JiIRTkJYBejggTl05MgRrrvuOpKSkjDGMG7cOFdb6GRHv379\n+Omnn1JaGgUKEVuX8NBDsGSJHUjHG8OGQcGCdqxkpQKdPpim8qTc+L84etT2gtqmjXdFR6tXQ1SU\nTQYvvODTUJTKkpDp7VQpfylaFHr3hq++sl1aZGboUNts1aN6RKmApglBqSzo3x+MsR3UZeS332DW\nLHj8cXAeyVAq4GlCUCoLKleG22+3A+ccy+ARyyFDoFw52zpJqWChCUGpLIqNhX37IL3OZxcssOMx\nP/MMFC/u19CUyhFNCDnUqlWrCx4ye+utt+jXr1+G6xUrVgyAHTt20LFjxzSXadmyJakr0VN76623\nOOZxqXrzzTdz4MCBDNZQOdW8OdSrZ/s3St0mwxgYPNj2kJrJv4BSAUcTQg516dKFadOmnTdt2rRp\ndOnSxav1L7nkkgyf9M1M6oTw/fffU6pUqWxvz9+MMSldYAQLEXuXsHYtzJt3/rw5c2yz1KFDwen+\nSamgkacSghu9X3fs2JHvvvsuZTCcLVu2sGPHDpo3b57yXEB0dDR16tThm2++uWD9LVu2ULt2bcB2\nK9G5c2dq1qzJHXfckdJdBNj2+cldZw8bNgyAMWPGsGPHDlq1akWrVq0A26XEnj17AHjjjTeoXbs2\ntWvXTuk6e8uWLdSsWZM+ffpQq1YtbrjhhvM+J9ns2bNp3Lgx9evX5/rrr2fXrl2AfdahZ8+e1KlT\nh7p166Z0ffHf//6X6OhooqKiuO666wA7PsRrr72Wss3atWuzZcsWtmzZQvXq1enevTu1a9dm69at\nae4fwLJly7jmmmuIioqiUaNGHD58mGuvvfa8br2bNWtGfHx8xn8oH+vcGSIizu8F9exZW3dQtart\npkKpYBNcTy0FoDJlytCoUSPmzJlD+/btmTZtGnfffTciQqFChZg5cyYlSpRgz549NGnShHbt2qU7\n5u/7779PkSJFWL9+PatXryY6Ojpl3ujRoylTpgxnzpzhuuuuY/Xq1QwcOJA33niD+fPnU65cufO2\ntXz5ciZNmsRvv/2GMYbGjRvTokULSpcuzaZNm5g6dSoffvghd999N19++SXdunU7b/1mzZqxdOlS\nRIQJEybwyiuv8PrrrzNy5EhKlizJmjVrADtmQWJiIn369GHhwoVUrVr1vH6J0rNp0yYmT55MkyZN\n0t2/GjVq0KlTJ7744gsaNmzIoUOHKFy4MPfffz8ff/wxb731Fhs3buTEiRNERUVl6e+WU4UKwQMP\nwOjR8NdfcMUVtjnqypUweTJ49FGoVNDIUwnBrd6vk4uNkhPCRx99BNjikGeffZaFCxeSL18+tm/f\nzq5duyifTh/KCxcuZODAgQDUrVuXunXrpsybPn0648ePJykpiYSEBNatW3fe/NQWL17MHXfckdLz\naIcOHVi0aBHt2rWjatWq1KtnxyPy7D7b07Zt2+jUqRMJCQmcOnWKqlWrArY7bM8istKlSzN79myu\nvfbalGW86SK7cuXKKckgvf0TESpUqEDDhg0BKFGiBAB33XUXI0eO5NVXX2XixIn06NEj08/LDf36\n2eEwx461A98MHQo1a0LXrq6Eo1SO5amE4Jb27dszaNAgVqxYwbFjx2jQoAFgO4tLTExk+fLlhIeH\nU6VKlWx1Nf3PP//w2muvsWzZMkqXLk2PHj2ytZ1kyV1ng+0+O60iowEDBvDoo4/Srl07FixYwPBs\n9Nvs2UU2nN9NtmcX2VndvyJFitCmTRu++eYbpk+fntLrqr9dcgncfTdMnGh7Mf3zT5gxw460plQw\nylN1CG4pVqwYrVq1olevXudVJid3/RweHs78+fP53//+l+F2rr32Wj7//HMA/vjjD1avXg3YrrOL\nFi1KyZIl2bVrF3PmzElZp3jx4hw+fPiCbTVv3pyvv/6aY8eOcfToUWbOnEnzLIzqfvDgQSpWtMNe\nTJ48OWV6mzZtePfdd1N+379/P02aNGHhwoX8888/wPldZK9YsQKAFStWpMxPLb39q169OgkJCSxb\ntgyAw4cPp4z90Lt3bwYOHEjDhg1TBuNxQ2wsHD5sf0ZHQ4cOma+jVKDShOAjXbp0IT4+/ryE0LVr\nV+Li4qhTpw5TpkzJdLCXfv36ceTIEWrWrMlzzz2XcqcRFRVF/fr1qVGjBvfcc895XWf37duXtm3b\nplQqJ4uOjqZHjx40atSIxo0b07t3b+rXr+/1/gwfPpy77rqLBg0anFc/MWTIEPbv30/t2rWJiopi\n/vz5REREMH78eDp06EBUVFRKt9V33nkn+/bto1atWrzzzjtcddVVaX5WevtXoEABvvjiCwYMGEBU\nVBRt2rRJuXNo0KABJUqUcH3MhEaNoEkTW6E8apRtgaRUsNLO7VRQ2rFjBy1btuTPP/8kX74Lr2v8\n+X+xdCnMnQvPPacJQQUm7dxO5VlTpkyhcePGjB49Os1k4G9NmthurjUZqGCnlcoq6HTv3p3u3bu7\nHYZSeY77l1c+EEzFXir36f+DUtkT9AmhUKFC7N27V08CCrDJYO/evRQqVMjtUJQKOkFfZFSpUiW2\nbdtGYmKi26GoAFGoUCEqVarkdhhKBZ2gTwjh4eEpT8gqpZTKvqAvMlJKKeUbmhCUUkoBmhCUUko5\ngupJZRFJBDLuECh95YA9PgzHVzSurNG4skbjypq8GldlY0xEZgsFVULICRGJ8+bRbX/TuLJG48oa\njStrQj0uLTJSSikFaEJQSinlCKWEMN7tANKhcWWNxpU1GlfWhHRcIVOHoJRSKmOhdIeglFIqA5oQ\nlFJKAXkwIYhIWxHZICKbReTpNOYXFJEvnPm/iUiVAImrh4gkisgq59XbDzFNFJHdIvJHOvNFRMY4\nMa8WkejcjsnLuFqKyEGPY/Wcn+K6VETmi8g6EVkrIrFpLOP3Y+ZlXH4/ZiJSSER+F5F4J67n01jG\n799HL+Py+/fR47PDRGSliHybxrzcPV7GmDzzAsKAv4DLgQJAPBCZapmHgA+c952BLwIkrh7AO34+\nXtcC0cAf6cy/GZgDCNAE+C1A4moJfOvC/1cFINp5XxzYmMbf0e/HzMu4/H7MnGNQzHkfDvwGNEm1\njBvfR2/i8vv30eOzHwU+T+vvldvHK6/dITQCNhtj/jbGnAKmAe1TLdMemOy8nwFcJ5Lrgx96E5ff\nGWMWAvsyWKQ9MMVYS4FSIlIhAOJyhTEmwRizwnl/GFgPVEy1mN+PmZdx+Z1zDI44v4Y7r9StWPz+\nffQyLleISCXgFmBCOovk6vHKawmhIrDV4/dtXPjFSFnGGJMEHATKBkBcAHc6xQwzROTSXI7JG97G\n7YarnVv+OSJSy98f7tyq18deXXpy9ZhlEBe4cMyc4o9VwG7gR2NMusfLj99Hb+ICd76PbwFPAmfT\nmZ+rxyuvJYRgNhuoYoypC/zIuasAdaEV2L5ZooCxwNf+/HARKQZ8CTxijDnkz8/OSCZxuXLMjDFn\njDH1gEpAIxGp7Y/PzYwXcfn9+ygitwK7jTHLc/uz0pPXEsJ2wDOTV3KmpbmMiOQHSgJ73Y7LGLPX\nGHPS+XUC0CCXY/KGN8fT74wxh5Jv+Y0x3wPhIlLOH58tIuHYk+5nxpiv0ljElWOWWVxuHjPnMw8A\n84G2qWa58X3MNC6Xvo9NgXYisgVbrNxaRD5NtUyuHq+8lhCWAdVEpKqIFMBWusxKtcws4D7nfUdg\nnnFqaNyMK1U5cztsObDbZgHdnZYzTYCDxpgEt4MSkfLJ5aYi0gj7f5zrJxHnMz8C1htj3khnMb8f\nM2/icuOYiUiEiJRy3hcG2gB/plrM799Hb+Jy4/tojHnGGFPJGFMFe46YZ4zplmqxXD1eQT+Epidj\nTJKI9AfmYlv2TDTGrBWREUCcMWYW9ovziYhsxlZcdg6QuAaKSDsgyYmrR27HJSJTsa1PyonINmAY\ntoINY8wHwPfYVjObgWNAz9yOycu4OgL9RCQJOA509kNSB3sFdy+wxil/BngWuMwjNjeOmTdxuXHM\nKgCTRSQMm4CmG2O+dfv76GVcfv8+psefx0u7rlBKKQXkvSIjpZRS2aQJQSmlFKAJQSmllEMTglJK\nKUATglJKKYcmBKWUUoAmBKWUUo7/B/Qoa0dIyaIhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}